<!doctype html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta content="IE=edge" http-equiv="X-UA-Compatible"/>
        <meta content="text/html; charset=UTF-8" http-equiv="content-type"/>
        <meta content="width=device-width, initial-scale=1" name="viewport"/>




    





    



    


<title>Naren Dasan</title>


    
    
        <meta name="author" content="Naren Dasan">
    
    
        <meta name="generator" content="Zola v0.16.1">

        <meta property="og:type" content="website">
        <meta property="og:url" content="https://www.narendasan.com/">
    
    
    
    
        <meta property="og:image" content="https:&#x2F;&#x2F;www.narendasan.com&#x2F;img&#x2F;favicon.ico">
    

    
    
        <meta property="twitter:card" content="summary_large_image">
        <meta property="twitter:url" content="https://www.narendasan.com/">
        
        
        
        <meta property="twitter:image" content="https:&#x2F;&#x2F;www.narendasan.com&#x2F;img&#x2F;favicon.ico">
        
    

        <link rel="canonical" href="https://www.narendasan.com/">
    
        <link rel="shortcut icon" type="image/x-icon" href="https://www.narendasan.com/img/favicon.ico">
    
        <script type="application/ld+json">
            {
                
                "url":"https://www.narendasan.com/",
                "@type":"WebSite",
                
                
                "author":{
                    "@type":"Person",
                    "name":"Naren Dasan"
                },
                "@context":"https://schema.org"
            }
        </script>



        <link rel="stylesheet" href="https://www.narendasan.com/style.css"/>

        <script>
            MathJax = {
              tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']]
              },
              svg: {
                fontCache: 'global'
              }
            };
            </script>
        <script type="text/javascript" id="MathJax-script" defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"></script>
    </head>
    <body theme="auto">
        <div class="w">
            <header>
                <a href="/">
                    <img src="/img/naren_logo_transparent.png" class="logo-img invertable" alt="About Nielsen Ramon header image">
                </a>

                <nav class="header-nav">
    
                    <a href="/about" >about</a>
    
                    <a href="/pubs" >publications</a>
    
                    <a href="/dir" >directory</a>
    
                    <a href="/blog" >blog</a>
    
                    <a href="/photos" >photos</a>
    
                    <a href="/rps" >reposts</a>
    
                </nav>


    

            </header>
            <main class="page-content" aria-label="Content">

<img src="/img/about.jpg" alt="About Nielsen Ramon header image" />
<p>
    My interests are in Robotics, Artificial Intelligence, and Tangible
    Interaction Design mostly surrounding systems with multiple agents. I've
    done other work in the past on computer vision, distributed and embedded
    systems. Right now, I am a PhD Student at the University of Colorado Boulder
    working on Human Robot Interaction research and working on the development
    of Autonomous Vehicles at NVIDIA. I completed my undergrad at the University
    of Illinois at Urbana-Champaign in Computer Engineering and my masters in
    Computer Science and Robotics at USC.
</p>

<h3>Academic and Professional Timeline</h3>
<ul>
    <li>
        2024-Present / University of Colorado Boulder - HIRO Lab / PhD Student
        advised by
        <a href="https://hiro-group.ronc.one//">Professor Alessandro Roncone</a>
    </li>
    <li>
        2022-2023 / University of Southern California - ICAROS / Graduate
        Research Assistant under
        <a href="https://icaros.usc.edu/">Professor Stefanos Nikolaidis</a>
    </li>
    <li>
        2021 / New York University - Game Innovation Lab / Graduate Research
        Assistant under
        <a href="http://julian.togelius.com/">Professor Julian Togelius</a>
    </li>
    <li>2018-Present / NVIDIA / Automotive Deep Learning Solution Architect</li>
    <li>2017 / NVIDIA / Automotive Deep Learning Solution Architect Intern</li>
    <li>
        2016 / University of Illinois Urbana-Champaign - Bretl Research Group /
        Undergraduate Research Assistant under
        <a href="http://bretl.csl.illinois.edu/people/">Professor Tim Bretl</a>
    </li>
    <li>2016 / Nest Labs / Embedded Software Engineering Intern</li>
    <li>
        2014 - 2018 / University of Illinois Urbana-Champaign - Vision Group /
        Undergraduate Research Assistant under
        <a href="http://dhoiem.cs.illinois.edu/">Professor Derek Hoiem</a>
    </li>
    <li>
        2013 - 2014 / University of Colorado Boulder - Correll Lab / High School
        Research Assistant under
        <a href="http://correll.cs.colorado.edu/?page_id=19"
            >Professor Nikolaus Correll</a
        >
    </li>
</ul>

<div class="spanning-bar"></div>

<h2>Most Recent Papers, Posters and Preprints</h2>

<ul class="article-list">
      
    <li class="article-list-item">
        <a href="https:&#x2F;&#x2F;ieeexplore.ieee.org&#x2F;document&#x2F;10559410" title="Selecting Source Tasks for Transfer Learning of Human Preferences">
            <h3>
                [IEEE RA-L] Selecting Source Tasks for Transfer Learning of Human Preferences
                <span class="icon icon-arrow-right"></span>
            </h3>
        </a>
        <p>We address the challenge of transferring human preferences for action selection from simpler source tasks to complex target tasks. Our goal is to enable robots to support humans proactively by predicting their actions — without requiring demonstrations of their preferred action sequences in the target task. Previous research has relied on human experts to design or select a simple source task that can be used to effectively learn and transfer human preferences to a known target. However, identifying such source tasks for new target tasks can demand substantial human effort. Thus, we focus on automating the selection of source tasks, introducing two new metrics. Our first metric selects source tasks in which human preferences can be accurately learned from demonstrations, while our second metric selects source tasks in which the learned preferences, although not as accurate, can match the preferred human actions in the target task. We evaluate our metrics in simulated tasks and two human-led assembly studies. Our results indicate that selecting high-scoring source tasks on either metric improves the accuracy of predicting human actions in the target task. Notably, tasks chosen by our second metric can be simpler than the first, sacrificing learning accuracy but preserving prediction accuracy.</p>
        <div class="article-list-footer">
            <span class="article-list-date">
                June 17, 2024
            </span>
            <span class="article-list-divider">-</span>
            <div class="article-list-tags">
                
                <a href="https:&#x2F;&#x2F;herambnemlekar.github.io&#x2F;">Heramb Nemlekar</a>
                
                <a href="">Naren Sivagnanadasan</a>
                
                <a href="">Subham Banga</a>
                
                <a href="https:&#x2F;&#x2F;www.neeldhanaraj.com&#x2F;">Neel Dhanaraj</a>
                
                <a href="https:&#x2F;&#x2F;viterbi.usc.edu&#x2F;directory&#x2F;faculty&#x2F;Gupta&#x2F;Satyandra">Satyandra K. Gupta</a>
                
                <a href="https:&#x2F;&#x2F;stefanosnikolaidis.net&#x2F;">Stefanos Nikolaidis</a>
                
            </div>
        </div>
    </li>
      
    <li class="article-list-item">
        <a href="https:&#x2F;&#x2F;pytorch.s3.amazonaws.com&#x2F;posters&#x2F;ptc2022&#x2F;C04.pdf" title="Torch-TensorRT: A Compiler for Accelerating PyTorch Inference Using TensorRT">
            <h3>
                [PyTorch Conference 2022] Torch-TensorRT: A Compiler for Accelerating PyTorch Inference Using TensorRT
                <span class="icon icon-arrow-right"></span>
            </h3>
        </a>
        <p>Torch-TensorRT is an open-source compiler targeting NVIDIA GPUs for high-performance deep-learning inference in PyTorch. It combines the usability of PyTorch with the performance of TensorRT allowing for easy optimization of inference workloads on NVIDIA GPUs. Torch-TensorRT supports all classes of optimizations in TensorRT including reduced mixed precision down to INT8, through simple Python &amp; C++ APIs designed to work directly from PyTorch. Torch-TensorRT outputs standard PyTorch modules as well as the TorchScript format to allow for a completely self-contained, portable, &amp; static module with TensorRT engines embedded as attributes</p>
        <div class="article-list-footer">
            <span class="article-list-date">
                December 2, 2022
            </span>
            <span class="article-list-divider">-</span>
            <div class="article-list-tags">
                
                <a href="">Naren Dasan</a>
                
                <a href="">Wei Wei</a>
                
                <a href="https:&#x2F;&#x2F;www.linkedin.com&#x2F;in&#x2F;dheerajperi&#x2F;">Dheeraj Peri</a>
                
                <a href="">Shirong Wu</a>
                
                <a href="https:&#x2F;&#x2F;ieeexplore.ieee.org&#x2F;author&#x2F;37085578871">Bo Wang</a>
                
                <a href="">Yinghai Lu</a>
                
                <a href="">Apurba Bose</a>
                
                <a href="">George Stefanakis</a>
                
                <a href="https:&#x2F;&#x2F;github.com&#x2F;ncomly-nvidia">Nick Comly</a>
                
            </div>
        </div>
    </li>
      
    <li class="article-list-item">
        <a href="https:&#x2F;&#x2F;s3.amazonaws.com&#x2F;assets.pytorch.org&#x2F;ptdd2021&#x2F;posters&#x2F;D2.png" title="Torch-TensorRT: Accelerating Inference Performance Directly from PyTorch using TensorRT">
            <h3>
                [PyTorch Developer Conference 2021] Torch-TensorRT: Accelerating Inference Performance Directly from PyTorch using TensorRT
                <span class="icon icon-arrow-right"></span>
            </h3>
        </a>
        <p>Torch-TensorRT is an open-source SDK designed to target NVIDIA GPUs for high-performance deep-learning inference. It combines the usability of PyTorch with the performance optimizations of TensorRT allowing for easy optimization of any inference workload on NVIDIA GPUs. Torch-TensorRT supports all optimizations of TensorRT including reduced mixed precision down to INT8, all within simple Python &amp; C++ APIs designed to work directly from PyTorch. Torch-TensorRT outputs the standard TorchScript format to allow for a completely self-contained, portable, &amp; static module with TensorRT engines embedded as attributes. Torch-TensorRT partitions the model into subgraphs based on TensorRT compatibility of each node. Compatible subgraphs are replaced with a single optimized TensorRT engine; the incompatible subgraphs “fallback” and run in native PyTorch. This fallback means there is no requirement for full model support by TensorRT, expanding Torch-TensorRT compatible models to all of TorchScript.</p>
        <div class="article-list-footer">
            <span class="article-list-date">
                December 2, 2021
            </span>
            <span class="article-list-divider">-</span>
            <div class="article-list-tags">
                
                <a href="">Naren Dasan</a>
                
                <a href="https:&#x2F;&#x2F;github.com&#x2F;ncomly-nvidia">Nick Comly</a>
                
                <a href="https:&#x2F;&#x2F;www.linkedin.com&#x2F;in&#x2F;dheerajperi&#x2F;">Dheeraj Peri</a>
                
                <a href="https:&#x2F;&#x2F;www.linkedin.com&#x2F;in&#x2F;anuragdixit11">Anurag Dixit</a>
                
                <a href="https:&#x2F;&#x2F;scholar.google.com&#x2F;citations?user=pXIRasMAAAAJ&amp;hl=en">Abhiram Iyer</a>
                
                <a href="https:&#x2F;&#x2F;ieeexplore.ieee.org&#x2F;author&#x2F;37085578871">Bo Wang</a>
                
                <a href="https:&#x2F;&#x2F;arvindpsridhar.com&#x2F;">Arvind Sridhar</a>
                
                <a href="https:&#x2F;&#x2F;github.com&#x2F;borisfom">Boris Fomitchev</a>
                
                <a href="">Josh Park</a>
                
            </div>
        </div>
    </li>
           
</ul>
<a href="/pubs#papers" , title="More publications">More Publications</a>

<div class="spanning-bar"></div>

<h2>Most Recent Talks</h2>

<ul class="article-list">
      
    <li class="article-list-item">
        <a href="https:&#x2F;&#x2F;events.rainfocus.com&#x2F;widget&#x2F;nvidia&#x2F;nvidiagtc&#x2F;sessioncatalog&#x2F;session&#x2F;1628545242933001TwnU" title="Accelerate PyTorch with TensorRT">
            <h3>
                [GPU Technology Conference Fall 2021] Accelerate PyTorch with TensorRT
                <span class="icon icon-arrow-right"></span>
            </h3>
        </a>
        <p>Learn how to accelerate PyTorch inference without leaving the framework with Torch-TensorRT. Torch-TensorRT makes the performance of NVIDIA’s TensorRT GPU optimizations available in PyTorch for any model. You&#x27;ll learn about the key capabilities of Torch-TensorRT, how to use them, and the performance benefits you can expect. We&#x27;ll walk you through how to easily transition from a trained model to an inference deployment fine-tuned for your specific hardware, all with just a few lines of familiar code. If you want more technical details, the second half of the talk will give you a chance to deep dive into how Torch-TensorRT operates, the mechanics of key features, and a few in-depth examples.</p>
        <div class="article-list-footer">
            <span class="article-list-date">
                November 8, 2021
            </span>
        </div>
    </li>
      
    <li class="article-list-item">
        <a href="https:&#x2F;&#x2F;www.nvidia.com&#x2F;en-us&#x2F;on-demand&#x2F;session&#x2F;gtcspring21-s31864&#x2F;" title="New Features in TRTorch, a PyTorch&#x2F;TorchScript Compiler Targeting NVIDIA GPUs Using TensorRT">
            <h3>
                [GPU Technology Conference Spring 2021] New Features in TRTorch, a PyTorch&#x2F;TorchScript Compiler Targeting NVIDIA GPUs Using TensorRT
                <span class="icon icon-arrow-right"></span>
            </h3>
        </a>
        <p>We&#x27;ll cover new features of TRTorch, a compiler for PyTorch and TorchScript that optimizes deep learning models for inference on NVIDIA GPUs. Programs are internally optimized using TensorRT but maintain full compatibility with standard PyTorch or TorchScript code. This allows users to continue to feel like they&#x27;re writing PyTorch code in their inference applications while fully leveraging TensorRT. We&#x27;ll discuss new capabilities enabled in recent releases of TRTorch, including direct integration into PyTorch and post-training quantization.</p>
        <div class="article-list-footer">
            <span class="article-list-date">
                April 2, 2021
            </span>
        </div>
    </li>
      
    <li class="article-list-item">
        <a href="https:&#x2F;&#x2F;www.nvidia.com&#x2F;en-us&#x2F;on-demand&#x2F;session&#x2F;gtcfall20-a21864&#x2F;" title="TRTorch: A PyTorch&#x2F;TorchScript Compiler Targeting NVIDIA GPUs Using TensorRT">
            <h3>
                [GPU Technology Conference Fall - Oct, 2020] TRTorch: A PyTorch&#x2F;TorchScript Compiler Targeting NVIDIA GPUs Using TensorRT
                <span class="icon icon-arrow-right"></span>
            </h3>
        </a>
        <p>We&#x27;ll dive into TRTorch, a new compiler for PyTorch and TorchScript that optimizes deep learning models for inference on NVIDIA GPUs. Programs are internally optimized using TensorRT but maintain full compatibility with standard PyTorch or TorchScript code. This allows users to continue to feel like they&#x27;re writing PyTorch code in their inference applications while fully leveraging TensorRT. We&#x27;ll cover how the compiler works internally and different ways to leverage the compiler.</p>
        <div class="article-list-footer">
            <span class="article-list-date">
                October 10, 2020
            </span>
        </div>
    </li>
             
</ul>
<a href="/pubs#talks" , title="More Talks">More Talks</a>

<div class="spanning-bar"></div>

<h2>Most Recent Posts</h2>

 
<ul class="article-list">
     
    <li class="article-list-item">
        <a href="https://www.narendasan.com/blog/waypoint-transformer/" title="Understanding the Waypoint Transformer">
            <h3>
                Understanding the Waypoint Transformer
                <span class="icon icon-arrow-right"></span>
            </h3>
        </a>
        <p>Supervised goal conditioned reinforcement learning using generated intermediate goals.</p>
        <div class="article-list-footer">
            <span class="article-list-date">
                October 27, 2024
            </span>
            <span class="article-list-divider">-</span>
            <div class="article-list-tags">
                
                <a href="/tags/rl">#rl</a>
                
                <a href="/tags/ai">#ai</a>
                
                <a href="/tags/transformers">#transformers</a>
                
            </div>
        </div>
    </li>
      
    <li class="article-list-item">
        <a href="https://www.narendasan.com/blog/pokemon-clip/" title="Building CLIP from Scratch to Classify Pokemon">
            <h3>
                Building CLIP from Scratch to Classify Pokemon
                <span class="icon icon-arrow-right"></span>
            </h3>
        </a>
        <p>Learning about how Contrastive Language-Image Pre-training (CLIP) works</p>
        <div class="article-list-footer">
            <span class="article-list-date">
                October 7, 2024
            </span>
            <span class="article-list-divider">-</span>
            <div class="article-list-tags">
                
                <a href="/tags/cv">#cv</a>
                
                <a href="/tags/ai">#ai</a>
                
                <a href="/tags/transformers">#transformers</a>
                
            </div>
        </div>
    </li>
      
    <li class="article-list-item">
        <a href="https://www.narendasan.com/blog/twitter-algo/" title="All Recommendation Engines Should Follow Twitter&#x27;s Example on Transparency">
            <h3>
                All Recommendation Engines Should Follow Twitter&#x27;s Example on Transparency
                <span class="icon icon-arrow-right"></span>
            </h3>
        </a>
        <p>Twitter released the source for its recommendation engine to be transparent about what it promotes and suppresses. Others should be required to do the same.</p>
        <div class="article-list-footer">
            <span class="article-list-date">
                April 1, 2023
            </span>
            <span class="article-list-divider">-</span>
            <div class="article-list-tags">
                
                <a href="/tags/commentary">#commentary</a>
                
            </div>
        </div>
    </li>
                                           
</ul>
<a href="/blog" , title="More posts">More Posts</a>


            </main>
        </div>
    </body>
    <footer>
        
        
        <nav>
        
            
                            <a href="/pdf/naren_dasan_resume_june_2021_with_citations.pdf" rel="me">cv</a>
            
                            <a href="https://scholar.google.com/citations?user=CDQ_1PQAAAAJ&hl=en" rel="me">google scholar</a>
            
                            <a href="https://twitter.com/narendasan" rel="me">twitter</a>
            
                            <a href="https://github.com/narendasan" rel="me">github</a>
            
                            <a href="https://sigmoid.social/@narendasan" rel="me">mastodon</a>
            
                            <a href="https://linkedin.com/in/narendasan" rel="me">linkedin</a>
            
                            <a href="mailto:naren@narendasan.com" rel="me">email</a>
            
        
            <a href="/rss.xml" rel="me">feed</a>
            <a href="/tags" rel="me">tags</a>
        </nav>
    </footer>
</html>

