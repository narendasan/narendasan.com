<!doctype html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta content="IE=edge" http-equiv="X-UA-Compatible"/>
        <meta content="text/html; charset=UTF-8" http-equiv="content-type"/>
        <meta content="width=device-width, initial-scale=1" name="viewport"/>


    



    



    



    



    


<title>Naren Dasan</title>


    
        <meta name="title" content="Publications">
    
    
        <meta name="author" content="Naren Dasan">
    
    
        <meta name="description" content="Publications">
    
        <meta name="generator" content="Zola v0.16.1">

        <meta property="og:type" content="website">
        <meta property="og:url" content="https://www.narendasan.com/pubs/">
    
        <meta property="og:site_name" content="">
    
    
        <meta property="og:title" content="Publications">
    
    
        <meta property="og:description" content="Publications">
    
    
        <meta property="og:image" content="https:&#x2F;&#x2F;www.narendasan.com&#x2F;img&#x2F;favicon.ico">
    

    
    
        <meta property="twitter:card" content="summary_large_image">
        <meta property="twitter:url" content="https://www.narendasan.com/pubs/">
        
        <meta property="twitter:title" content="Publications">
        
        
        <meta property="twitter:description" content="Publications">
        
        
        <meta property="twitter:image" content="https:&#x2F;&#x2F;www.narendasan.com&#x2F;img&#x2F;favicon.ico">
        
    

        <link rel="canonical" href="https://www.narendasan.com/pubs/">
    
        <link rel="shortcut icon" type="image/x-icon" href="https://www.narendasan.com/img/favicon.ico">
    
        <script type="application/ld+json">
            {
                "description":"Publications",
                "url":"https://www.narendasan.com/pubs/",
                "@type":"WebSite",
                "headline":"Publications",
                "name":"Publications",
                "author":{
                    "@type":"Person",
                    "name":"Naren Dasan"
                },
                "@context":"https://schema.org"
            }
        </script>



        <link rel="stylesheet" href="https://www.narendasan.com/style.css"/>

        <script>
            MathJax = {
              tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']]
              },
              svg: {
                fontCache: 'global'
              }
            };
            </script>
        <script type="text/javascript" id="MathJax-script" defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"></script>
    </head>
    <body theme="auto">
        <div class="w">
            <header>
                <a href="/">
                    <img src="/img/naren_logo_transparent.png" class="logo-img invertable" alt="About Nielsen Ramon header image">
                </a>

                <nav class="header-nav">
    
                    <a href="/about" >about</a>
    
                    <a href="/pubs" >publications</a>
    
                    <a href="/dir" >directory</a>
    
                    <a href="/blog" >blog</a>
    
                    <a href="/photos" >photos</a>
    
                    <a href="/rps" >reposts</a>
    
                </nav>


<p><a href=".."><-</a>&ensp; pubs</p>
<h1 id="papers">
    Papers, Posters and Preprints
</h1>

            </header>
            <main class="page-content" aria-label="Content">

<ul class="article-list">
    
    
    <li class="article-list-item">
        <a href="https:&#x2F;&#x2F;ieeexplore.ieee.org&#x2F;document&#x2F;10559410" title="Selecting Source Tasks for Transfer Learning of Human Preferences">
            <h3>
              [IEEE RA-L] Selecting Source Tasks for Transfer Learning of Human Preferences
              <span class="icon icon-arrow-right"></span>
            </h3>
        </a>
        <p>We address the challenge of transferring human preferences for action selection from simpler source tasks to complex target tasks. Our goal is to enable robots to support humans proactively by predicting their actions — without requiring demonstrations of their preferred action sequences in the target task. Previous research has relied on human experts to design or select a simple source task that can be used to effectively learn and transfer human preferences to a known target. However, identifying such source tasks for new target tasks can demand substantial human effort. Thus, we focus on automating the selection of source tasks, introducing two new metrics. Our first metric selects source tasks in which human preferences can be accurately learned from demonstrations, while our second metric selects source tasks in which the learned preferences, although not as accurate, can match the preferred human actions in the target task. We evaluate our metrics in simulated tasks and two human-led assembly studies. Our results indicate that selecting high-scoring source tasks on either metric improves the accuracy of predicting human actions in the target task. Notably, tasks chosen by our second metric can be simpler than the first, sacrificing learning accuracy but preserving prediction accuracy.</p>
        <div class="article-list-footer">
            <span class="article-list-date">
                  June 17, 2024
            </span>
            <span class="article-list-divider">-</span>
            <div class="article-list-tags">
                
                    <a href="https:&#x2F;&#x2F;herambnemlekar.github.io&#x2F;">Heramb Nemlekar</a>
                
                    <a href="">Naren Sivagnanadasan</a>
                
                    <a href="">Subham Banga</a>
                
                    <a href="https:&#x2F;&#x2F;www.neeldhanaraj.com&#x2F;">Neel Dhanaraj</a>
                
                    <a href="https:&#x2F;&#x2F;viterbi.usc.edu&#x2F;directory&#x2F;faculty&#x2F;Gupta&#x2F;Satyandra">Satyandra K. Gupta</a>
                
                    <a href="https:&#x2F;&#x2F;stefanosnikolaidis.net&#x2F;">Stefanos Nikolaidis</a>
                
            </div>
        </div>
    </li>
    
    <li class="article-list-item">
        <a href="https:&#x2F;&#x2F;pytorch.s3.amazonaws.com&#x2F;posters&#x2F;ptc2022&#x2F;C04.pdf" title="Torch-TensorRT: A Compiler for Accelerating PyTorch Inference Using TensorRT">
            <h3>
              [PyTorch Conference 2022] Torch-TensorRT: A Compiler for Accelerating PyTorch Inference Using TensorRT
              <span class="icon icon-arrow-right"></span>
            </h3>
        </a>
        <p>Torch-TensorRT is an open-source compiler targeting NVIDIA GPUs for high-performance deep-learning inference in PyTorch. It combines the usability of PyTorch with the performance of TensorRT allowing for easy optimization of inference workloads on NVIDIA GPUs. Torch-TensorRT supports all classes of optimizations in TensorRT including reduced mixed precision down to INT8, through simple Python &amp; C++ APIs designed to work directly from PyTorch. Torch-TensorRT outputs standard PyTorch modules as well as the TorchScript format to allow for a completely self-contained, portable, &amp; static module with TensorRT engines embedded as attributes</p>
        <div class="article-list-footer">
            <span class="article-list-date">
                  December 2, 2022
            </span>
            <span class="article-list-divider">-</span>
            <div class="article-list-tags">
                
                    <a href="">Naren Dasan</a>
                
                    <a href="">Wei Wei</a>
                
                    <a href="https:&#x2F;&#x2F;www.linkedin.com&#x2F;in&#x2F;dheerajperi&#x2F;">Dheeraj Peri</a>
                
                    <a href="">Shirong Wu</a>
                
                    <a href="https:&#x2F;&#x2F;ieeexplore.ieee.org&#x2F;author&#x2F;37085578871">Bo Wang</a>
                
                    <a href="">Yinghai Lu</a>
                
                    <a href="">Apurba Bose</a>
                
                    <a href="">George Stefanakis</a>
                
                    <a href="https:&#x2F;&#x2F;github.com&#x2F;ncomly-nvidia">Nick Comly</a>
                
            </div>
        </div>
    </li>
    
    <li class="article-list-item">
        <a href="https:&#x2F;&#x2F;s3.amazonaws.com&#x2F;assets.pytorch.org&#x2F;ptdd2021&#x2F;posters&#x2F;D2.png" title="Torch-TensorRT: Accelerating Inference Performance Directly from PyTorch using TensorRT">
            <h3>
              [PyTorch Developer Conference 2021] Torch-TensorRT: Accelerating Inference Performance Directly from PyTorch using TensorRT
              <span class="icon icon-arrow-right"></span>
            </h3>
        </a>
        <p>Torch-TensorRT is an open-source SDK designed to target NVIDIA GPUs for high-performance deep-learning inference. It combines the usability of PyTorch with the performance optimizations of TensorRT allowing for easy optimization of any inference workload on NVIDIA GPUs. Torch-TensorRT supports all optimizations of TensorRT including reduced mixed precision down to INT8, all within simple Python &amp; C++ APIs designed to work directly from PyTorch. Torch-TensorRT outputs the standard TorchScript format to allow for a completely self-contained, portable, &amp; static module with TensorRT engines embedded as attributes. Torch-TensorRT partitions the model into subgraphs based on TensorRT compatibility of each node. Compatible subgraphs are replaced with a single optimized TensorRT engine; the incompatible subgraphs “fallback” and run in native PyTorch. This fallback means there is no requirement for full model support by TensorRT, expanding Torch-TensorRT compatible models to all of TorchScript.</p>
        <div class="article-list-footer">
            <span class="article-list-date">
                  December 2, 2021
            </span>
            <span class="article-list-divider">-</span>
            <div class="article-list-tags">
                
                    <a href="">Naren Dasan</a>
                
                    <a href="https:&#x2F;&#x2F;github.com&#x2F;ncomly-nvidia">Nick Comly</a>
                
                    <a href="https:&#x2F;&#x2F;www.linkedin.com&#x2F;in&#x2F;dheerajperi&#x2F;">Dheeraj Peri</a>
                
                    <a href="https:&#x2F;&#x2F;www.linkedin.com&#x2F;in&#x2F;anuragdixit11">Anurag Dixit</a>
                
                    <a href="https:&#x2F;&#x2F;scholar.google.com&#x2F;citations?user=pXIRasMAAAAJ&amp;hl=en">Abhiram Iyer</a>
                
                    <a href="https:&#x2F;&#x2F;ieeexplore.ieee.org&#x2F;author&#x2F;37085578871">Bo Wang</a>
                
                    <a href="https:&#x2F;&#x2F;arvindpsridhar.com&#x2F;">Arvind Sridhar</a>
                
                    <a href="https:&#x2F;&#x2F;github.com&#x2F;borisfom">Boris Fomitchev</a>
                
                    <a href="">Josh Park</a>
                
            </div>
        </div>
    </li>
    
    <li class="article-list-item">
        <a href="https:&#x2F;&#x2F;assets.pytorch.org&#x2F;pted2021&#x2F;posters&#x2F;I6.png" title="TRTorch: A Compiler for TorchScript Targeting NVIDIA GPUs with TensorRT">
            <h3>
              [PTED] TRTorch: A Compiler for TorchScript Targeting NVIDIA GPUs with TensorRT
              <span class="icon icon-arrow-right"></span>
            </h3>
        </a>
        <p>We present TRTorch, a compiler for PyTorch and TorchScript targeting NVIDIA GPUs, which combines the usability of PyTorch with the performance of TensorRT allowing users to optimize easily inference workloads on NVIDIA GPUs. For experimentation and the development of machine learning models, few tools are as approachable as PyTorch. However, some of the features that make PyTorch great for development make it hard to deploy. With TorchScript, PyTorch now has solid tooling for addressing some of these problems. TorchScript removes the dependency on Python and produces portable, self contained, static representations of code and weights. In addition to portability, users also look to optimize performance in deployment. On NVIDIA GPUs, TensorRT, NVIDIA’s deep learning optimizer, provides the capability to maximize performance of workloads by tuning the execution of models for specific target hardware. TRTorch merges the benefits of TorchScript and TensorRT to simplify conducting optimization including post training quantization by leveraging common PyTorch tooling. It can be used directly from PyTorch as a TorchScript Backend, via CLI or embedded (C++&#x2F;Python) in an application to easily increase inference performance.</p>
        <div class="article-list-footer">
            <span class="article-list-date">
                  April 21, 2021
            </span>
            <span class="article-list-divider">-</span>
            <div class="article-list-tags">
                
                    <a href="">Naren Dasan</a>
                
            </div>
        </div>
    </li>
    
    <li class="article-list-item">
        <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1606.05002" title="3DFS: deformable dense depth fusion and segmentation for object reconstruction from a handheld camera">
            <h3>
              [arXiv:1606.05002] 3DFS: deformable dense depth fusion and segmentation for object reconstruction from a handheld camera
              <span class="icon icon-arrow-right"></span>
            </h3>
        </a>
        <p>We propose an approach for 3D reconstruction and segmentation of a single object placed on a flat surface from an input video. Our approach is to perform dense depth map estimation for multiple views using a proposed objective function that preserves detail. The resulting depth maps are then fused using a proposed implicit surface function that is robust to estimation error, producing a smooth surface reconstruction of the entire scene. Finally, the object is segmented from the remaining scene using a proposed 2D-3D segmentation that incorporates image and depth cues with priors and regularization over the 3D volume and 2D segmentations. We evaluate 3D reconstructions qualitatively on our Object-Videos dataset, comparing to fusion, multiview stereo, and segmentation baselines. We also quantitatively evaluate the dense depth estimation using the RGBD Scenes V2 dataset [Henry et al. 2013] and the segmentation using keyframe annotations of the Object-Videos dataset.</p>
        <div class="article-list-footer">
            <span class="article-list-date">
                  June 15, 2016
            </span>
            <span class="article-list-divider">-</span>
            <div class="article-list-tags">
                
                    <a href="http:&#x2F;&#x2F;tanmaygupta.info">Tanmay Gupta</a>
                
                    <a href="http:&#x2F;&#x2F;research.dshin.org&#x2F;">Daeyun Shin</a>
                
                    <a href="">Naren Sivagnanadasan</a>
                
                    <a href="http:&#x2F;&#x2F;dhoiem.cs.illinois.edu">Derek Hoiem</a>
                
            </div>
        </div>
    </li>
    
    <li class="article-list-item">
        <a href="https:&#x2F;&#x2F;dl.acm.org&#x2F;citation.cfm?id=2540967" title="Gesture based distributed user interaction system for a reconfigurable self-organizing smart wall">
            <h3>
              [TEI &#x27;14] Gesture based distributed user interaction system for a reconfigurable self-organizing smart wall
              <span class="icon icon-arrow-right"></span>
            </h3>
        </a>
        <p>We describe user interactions with the self-organized amorphous wall, a modular, fully distributed system of computational building blocks that communicate locally for creating smart surfaces and functional room dividers. We describe a menu and a widget-based approach in which functions are color-coded and can be selected by dragging them from module to module on the surface of the wall. We also propose an on-off switch gesture and a dial gesture each spanning multiple units as canonical input mechanisms that are realized in a fully distributed way.</p>
        <div class="article-list-footer">
            <span class="article-list-date">
                  February 14, 2014
            </span>
            <span class="article-list-divider">-</span>
            <div class="article-list-tags">
                
                    <a href="">Nicholas Farrow</a>
                
                    <a href="">Naren Sivagnanadasan</a>
                
                    <a href="http:&#x2F;&#x2F;correll.cs.colorado.edu&#x2F;?page_id=19">Nikolaus Correll</a>
                
            </div>
        </div>
    </li>
    
</ul>

<h2 id="talks">Talks</h2>

<ul class="article-list">
    
    
    <li class="article-list-item">
        <a href="https:&#x2F;&#x2F;events.rainfocus.com&#x2F;widget&#x2F;nvidia&#x2F;nvidiagtc&#x2F;sessioncatalog&#x2F;session&#x2F;1628545242933001TwnU" title="Accelerate PyTorch with TensorRT">
            <h3>
              [GPU Technology Conference Fall 2021] Accelerate PyTorch with TensorRT
              <span class="icon icon-arrow-right"></span>
            </h3>
        </a>
        <p>Learn how to accelerate PyTorch inference without leaving the framework with Torch-TensorRT. Torch-TensorRT makes the performance of NVIDIA’s TensorRT GPU optimizations available in PyTorch for any model. You&#x27;ll learn about the key capabilities of Torch-TensorRT, how to use them, and the performance benefits you can expect. We&#x27;ll walk you through how to easily transition from a trained model to an inference deployment fine-tuned for your specific hardware, all with just a few lines of familiar code. If you want more technical details, the second half of the talk will give you a chance to deep dive into how Torch-TensorRT operates, the mechanics of key features, and a few in-depth examples.</p>
        <div class="article-list-footer">
            <span class="article-list-date">
                  November 8, 2021
            </span>
        </div>
    </li>
    
    <li class="article-list-item">
        <a href="https:&#x2F;&#x2F;www.nvidia.com&#x2F;en-us&#x2F;on-demand&#x2F;session&#x2F;gtcspring21-s31864&#x2F;" title="New Features in TRTorch, a PyTorch&#x2F;TorchScript Compiler Targeting NVIDIA GPUs Using TensorRT">
            <h3>
              [GPU Technology Conference Spring 2021] New Features in TRTorch, a PyTorch&#x2F;TorchScript Compiler Targeting NVIDIA GPUs Using TensorRT
              <span class="icon icon-arrow-right"></span>
            </h3>
        </a>
        <p>We&#x27;ll cover new features of TRTorch, a compiler for PyTorch and TorchScript that optimizes deep learning models for inference on NVIDIA GPUs. Programs are internally optimized using TensorRT but maintain full compatibility with standard PyTorch or TorchScript code. This allows users to continue to feel like they&#x27;re writing PyTorch code in their inference applications while fully leveraging TensorRT. We&#x27;ll discuss new capabilities enabled in recent releases of TRTorch, including direct integration into PyTorch and post-training quantization.</p>
        <div class="article-list-footer">
            <span class="article-list-date">
                  April 2, 2021
            </span>
        </div>
    </li>
    
    <li class="article-list-item">
        <a href="https:&#x2F;&#x2F;www.nvidia.com&#x2F;en-us&#x2F;on-demand&#x2F;session&#x2F;gtcfall20-a21864&#x2F;" title="TRTorch: A PyTorch&#x2F;TorchScript Compiler Targeting NVIDIA GPUs Using TensorRT">
            <h3>
              [GPU Technology Conference Fall - Oct, 2020] TRTorch: A PyTorch&#x2F;TorchScript Compiler Targeting NVIDIA GPUs Using TensorRT
              <span class="icon icon-arrow-right"></span>
            </h3>
        </a>
        <p>We&#x27;ll dive into TRTorch, a new compiler for PyTorch and TorchScript that optimizes deep learning models for inference on NVIDIA GPUs. Programs are internally optimized using TensorRT but maintain full compatibility with standard PyTorch or TorchScript code. This allows users to continue to feel like they&#x27;re writing PyTorch code in their inference applications while fully leveraging TensorRT. We&#x27;ll cover how the compiler works internally and different ways to leverage the compiler.</p>
        <div class="article-list-footer">
            <span class="article-list-date">
                  October 10, 2020
            </span>
        </div>
    </li>
    
    <li class="article-list-item">
        <a href="https:&#x2F;&#x2F;developer.nvidia.com&#x2F;gtc&#x2F;2020&#x2F;video&#x2F;s21671-vid" title="PyTorch-TensorRT: Accelerating Inference in PyTorch with TensorRT">
            <h3>
              [GPU Technology Conference - 2020] PyTorch-TensorRT: Accelerating Inference in PyTorch with TensorRT
              <span class="icon icon-arrow-right"></span>
            </h3>
        </a>
        <p>TensorRT is a deep-learning inference optimizer and runtime to optimize networks for GPUs and the NVIDIA Deep Learning Accelerator (DLA). Typically, the procedure to optimize models with TensorRT is to first convert a trained model to an intermediary format, such as ONNX, and then parse the file with a TensorRT parser. This works well for networks using common architectures and common operators; however, with the rapid pace of model development, sometimes a DL framework like Tensorflow has ops that are not supported in TensorRT. One solution is to implement plugins for these ops. Another is to use a tool like TF-TRT, which will convert supportable subgraphs to TensorRT and use Tensorflow implementations for the rest. We&#x27;ll demonstrate the same ability with PyTorch with our new tool PTH-TRT, as well leveraging the PyTorch API&#x27;s great composability features to allow users to reuse their TensorRT-compatible networks in larger, more complex ones.</p>
        <div class="article-list-footer">
            <span class="article-list-date">
                  April 4, 2020
            </span>
        </div>
    </li>
    
    <li class="article-list-item">
        <a href="https:&#x2F;&#x2F;github.com&#x2F;narendasan&#x2F;intro_to_cnns" title="Lecture: Intro to Convolutional Neural Nets">
            <h3>
              [University of Illinois Urbana-Champaign - CS@Illinois SAIL] Lecture: Intro to Convolutional Neural Nets
              <span class="icon icon-arrow-right"></span>
            </h3>
        </a>
        <p>A quick crash course in using neural nets for Computer Vision. Builds up from logistic regression to CNNs with implementations in PyTorch</p>
        <div class="article-list-footer">
            <span class="article-list-date">
                  April 7, 2018
            </span>
        </div>
    </li>
    
    <li class="article-list-item">
        <a href="https:&#x2F;&#x2F;www.colorado.edu&#x2F;techtalks&#x2F;2017&#x2F;08&#x2F;23&#x2F;28-intro-convolutional-neural-nets-and-implications-deep-learning-and-ai" title="Intro to Convolutional Neural Nets and Implications of Deep Learning and AI">
            <h3>
              [University of Colorado - OIT Tech Talk] Intro to Convolutional Neural Nets and Implications of Deep Learning and AI
              <span class="icon icon-arrow-right"></span>
            </h3>
        </a>
        <p>Artificial Intelligence has entered a great age of productivity, with massive strides in Computer Vision, Natural Language Processing and Task Learning being enabled by the exponential growth in data availability and the computing power enabled by General Purpose GPU (GPGPU) computing. Developers can now create near state of the art AI applications on their laptops. This talk will cover one of the main tools in deep learning and AI: Convolutional Neural Networks (CNN), how to build one, and how to apply it to a problem like handwriting recognition. It will then explore some of the current problems and approaches in the field of AI such as self driving cars, machine translation, and robotics.</p>
        <div class="article-list-footer">
            <span class="article-list-date">
                  August 23, 2017
            </span>
        </div>
    </li>
    
    <li class="article-list-item">
        <a href="https:&#x2F;&#x2F;www.ted.com&#x2F;tedx&#x2F;events&#x2F;11347" title="Navigating Learning in the Multidisciplinary World">
            <h3>
              [TEDxMileHigh - Emergence] Navigating Learning in the Multidisciplinary World
              <span class="icon icon-arrow-right"></span>
            </h3>
        </a>
        <p>What skills are necessary to succeed in a world that&#x27;s becoming more and more complex? Is it better to specialize, focusing on one subject area? Or is it better to have an inter-disciplinary approach? Why the future of work lies not within specialization, but in the ability to draw on design thinking and immediate problem solving to solve the world&#x27;s big challenges.</p>
        <div class="article-list-footer">
            <span class="article-list-date">
                  April 16, 2014
            </span>
        </div>
    </li>
    
</ul>

            </main>
        </div>
    </body>
    <footer>
        
        
        <nav>
        
            
                            <a href="/pdf/naren_dasan_resume_june_2021_with_citations.pdf" rel="me">cv</a>
            
                            <a href="https://scholar.google.com/citations?user=CDQ_1PQAAAAJ&hl=en" rel="me">google scholar</a>
            
                            <a href="https://twitter.com/narendasan" rel="me">twitter</a>
            
                            <a href="https://github.com/narendasan" rel="me">github</a>
            
                            <a href="https://sigmoid.social/@narendasan" rel="me">mastodon</a>
            
                            <a href="https://linkedin.com/in/narendasan" rel="me">linkedin</a>
            
                            <a href="mailto:naren@narendasan.com" rel="me">email</a>
            
        
            <a href="/rss.xml" rel="me">feed</a>
            <a href="/tags" rel="me">tags</a>
        </nav>
    </footer>
</html>

